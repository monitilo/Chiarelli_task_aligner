# Aligner Wrapper Project

This repository contains a Dockerized Python wrapper around `bwa mem` for NGS read alignment, along with automated tests and reporting.

---

## Contents

- `aligner.py` — Main alignment wrapper script  
- `test_aligner.py` — Pytest-based automated tests validating key requirements  
- `generate_report.py` — Converts CSV test output into a human readable Markdown report  
- `test_cases/` — Sample input files for testing
- `requirements.txt` — Python dependencies  
- `Dockerfile` — Docker environment setup  
- `README.md` — This file 

---

## Usage Instructions

### Running the Aligner, aligner.py

python aligner.py \
  -r1 <read1.fastq.gz> \
  -r2<read2.fastq.gz> \
  -f <reference_genome.fasta> \
  -o <output_dir> \
  -t <threads> \
  --stats <stats_report.txt> \
  [--keep_intermediates yes|no]

### input Argument

Argument	Description
-r1, --read1	Path to Read 1 FASTQ.gz file (required)
-r2, --read2	Path to Read 2 FASTQ.gz file (optional)
-f, --reference	Reference genome FASTA (must be pre-indexed with bwa index)
-o, --output_dir	Output directory (created if it doesn't exist)
-t, --threads	Number of threads to use (default: 4)
--stats	Optional file to store stats report (default: results.txt)
--keep_intermediates	yes or no. Whether to retain SAM/BAM intermediates (default: no)


#### output

Aligned BAM

results.txt with alignment stats and CPU/memory usage

Optional Intermediate files (SAM, sorted BAM) if --keep_intermediates yes



### Running the pytests, test_aligner.py

pytest test_aligner.py

Runs a set of functional tests using sample data in test_cases/

Generates a CSV with test results (output/test_results.csv)

Connected to conftest.py internally and Automatically invokes generate_report.py to create test_report.md

### conftest.py

Pytest hook that collects test metadata (pass/fail, acceptance criteria, reads, reference, threads)

Writes results to test_results/test_results.csv

Automatically calls generate_report.py after test completion

### generate_report.py

Generates a human-readable Markdown summary of the test results.


Can be run independently:
python generate_report.py -i output/test_results.csv -o output/test_report.md

-i, --input: CSV input file (generated by pythest test_results.py)
-o, --output: Markdown output file

# Script Logic and Design
## Alignment Logic
Runs bwa mem with given FASTQ and reference

Converts SAM to sorted BAM with samtools

Captures alignment metrics via samtools flagstat

Measures CPU and memory in real time with psutil

## Processing Flow
Validate arguments and files

Align reads

Post-process output files

Generate stats and monitor system usage

(If tests) compare results to acceptance criteria

Generate human-readable report

## Notes & Observations
### CPU Usage Limitation
Despite using bwa mem -t <n>, actual CPU usage often exceeds the expected core count.

Example: For 1M reads, hg38 and 4 threads, CPU usage can peak at 470%.

This behavior causes the REQ05 test to FAIL, as it expects CPU usage to stay within declared limits.

Python-based CPU restriction is proved challenging due to bwa’s internal multi-threading model. The current approach uses the -t flag in bwa and monitors actual usage with psutil but do not enforce it.


### Reference Genomes & Test Design
Tests use a mix of:

- Full hg38 — realistic scenario (~6GB)

- chr21 & chr22 only — faster test cycles

Including the full hg38 reference directly in the repository adds significant bulk, which can exceed GitHub’s file size limits. To address this:

Large hg38 file is split into parts (≤2GB each) for storage and version control.

A dedicated merge script is included that automatically recombines these parts before running tests or analysis.

Docker & End-to-End Testing
The Docker image is built to support end-to-end workflows, including:

Automatic merging of reference genome parts on container start or test initialization.

Running full alignment tests with the complete hg38 reference seamlessly.

This setup ensures reproducibility while respecting file size constraints imposed by GitHub.

# Docker Instructions

## Build the Docker image:
To create the Docker image, run:

docker build -t chiarelli-aligner:latest .

This command builds the image and copies the repository's file structure into the container.


## Run container interactively :

To explore and use the scripts and test data interactively, run:

docker run --rm -it chiarelli-aligner:latest

This will start a shell session inside the container, with the directory structure mirroring the repository.

## Run the aligner in a container:
To verify that the aligner works and shows the help message:

docker run --rm chiarelli-aligner:latest python aligner.py --help


## Run tests and generate report:

To execute the test suite and generate a Markdown report, mount the output folder from your local system:

docker run --rm -v "./output:/app/output" chiarelli-aligner:latest pytest test_aligner.py

This will:

Run pytest inside the container

Create test results in CSV format

Automatically generate a human-readable test_report.md

he final output will appear in your local ./output/ directory.


# Software Requirements
The following tools and libraries are required to run the pipeline outside Docker:

## System Dependencies
bwa — Aligner used under the hood (bwa mem)

samtools — For SAM/BAM conversion and sorting

gzip — For handling compressed FASTQ files

## Python Dependencies
Installed via requirements.txt:

psutil==7.0.0 — For monitoring CPU and memory usage

pysam==0.23.3 — For working with SAM/BAM files

pytest==8.4.1 — For automated testing

Note: All dependencies are pre-installed in the provided Docker image. No additional setup is needed when using Docker.

